data:	./sport_data/
vocab:	./sport_data/vocab.txt
vocab_size:	60000
type_num:	4
head_num:	4
log:	./sport_data/log/
epoch:	10
batch_size:	32
param_init:	0.1
optim:	adam
learning_rate:	0.0005
max_grad_norm:	8
window_size:	[1, 2, 3]
filter_size:	128
learning_rate_decay:	0.5
schedule:	True
start_decay_at:	2
emb_size:	128
encoder_hidden_size:	128
decoder_hidden_size:	256
num_layers:	2
bidirec:	True
dropout:	0.1
max_tgt_len:	30
max_sentence_len:	100
eval_interval:	500
save_interval:	2000
max_generator_batches:	32
metric:	['bleu', 'xent']
shared_vocab:	True
beam_size:	10

graph2gru(
  (embedding): Embedding(60000, 128)
  (encoder): Memory_Network(
    (embedding): Embedding(60000, 128)
    (bert): BERT(
      (position_emb): Embedding(101, 128)
      (encoder): Encoder(
        (layers): ModuleList(
          (0): EncoderLayer(
            (self_attn): MultiHeadedAttention(
              (linears): ModuleList(
                (0): Linear(in_features=128, out_features=128, bias=True)
                (1): Linear(in_features=128, out_features=128, bias=True)
                (2): Linear(in_features=128, out_features=128, bias=True)
                (3): Linear(in_features=128, out_features=128, bias=True)
              )
            )
            (feed_forward): PositionwiseFeedForward(
              (w_1): Linear(in_features=128, out_features=128, bias=True)
              (w_2): Linear(in_features=128, out_features=128, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (sublayer): ModuleList(
              (0): SublayerConnection(
                (norm): LayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (1): SublayerConnection(
                (norm): LayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
          )
          (1): EncoderLayer(
            (self_attn): MultiHeadedAttention(
              (linears): ModuleList(
                (0): Linear(in_features=128, out_features=128, bias=True)
                (1): Linear(in_features=128, out_features=128, bias=True)
                (2): Linear(in_features=128, out_features=128, bias=True)
                (3): Linear(in_features=128, out_features=128, bias=True)
              )
            )
            (feed_forward): PositionwiseFeedForward(
              (w_1): Linear(in_features=128, out_features=128, bias=True)
              (w_2): Linear(in_features=128, out_features=128, bias=True)
              (dropout): Dropout(p=0.1, inplace=False)
            )
            (sublayer): ModuleList(
              (0): SublayerConnection(
                (norm): LayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
              (1): SublayerConnection(
                (norm): LayerNorm()
                (dropout): Dropout(p=0.1, inplace=False)
              )
            )
          )
        )
        (norm): LayerNorm()
      )
      (word_emb): Embedding(60000, 128)
      (generator): Generator(
        (ff): Sequential(
          (0): Linear(in_features=128, out_features=128, bias=True)
          (1): ReLU()
        )
        (emb): Embedding(60000, 128)
      )
    )
    (gcn): GraphConvolution(
      (linear): Linear(in_features=128, out_features=128, bias=True)
      (activation): Tanh()
    )
    (out): Linear(in_features=128, out_features=256, bias=True)
    (tanh): Tanh()
  )
  (decoder): rnn_decoder(
    (embedding): Embedding(60000, 128)
    (rnn): StackedGRU(
      (dropout): Dropout(p=0.1, inplace=False)
      (layers): ModuleList(
        (0): GRUCell(128, 256)
        (1): GRUCell(256, 256)
      )
    )
    (linear): Linear(in_features=256, out_features=60000, bias=True)
    (attention): global_attention(
      (linear_in): Linear(in_features=256, out_features=256, bias=True)
      (linear_out): Linear(in_features=512, out_features=256, bias=True)
      (softmax): Softmax(dim=-1)
      (tanh): Tanh()
    )
    (dropout): Dropout(p=0.1, inplace=False)
  )
  (state_wh): Linear(in_features=256, out_features=512, bias=True)
  (tanh): Tanh()
  (criterion): CrossEntropyLoss()
  (log_softmax): LogSoftmax()
)

total number of parameters: 24398304

time: 226.494, epoch:   1, updates:      500, train loss:  4.532, train acc: 0.053
time: 241.279, epoch:   1, updates:     1000, train loss:  4.246, train acc: 0.065
time: 80.282, epoch:   2, updates:     1500, train loss:  1.382, train acc: 0.023
time: 233.242, epoch:   2, updates:     2000, train loss:  4.036, train acc: 0.069
time: 254.374, epoch:   2, updates:     2500, train loss:  4.033, train acc: 0.069
time: 170.793, epoch:   3, updates:     3000, train loss:  2.654, train acc: 0.049
time: 241.616, epoch:   3, updates:     3500, train loss:  3.865, train acc: 0.072
time:  4.984, epoch:   4, updates:     4000, train loss:  0.078, train acc: 0.001
time: 245.520, epoch:   4, updates:     4500, train loss:  3.745, train acc: 0.074
time: 245.779, epoch:   4, updates:     5000, train loss:  3.713, train acc: 0.074
time: 87.906, epoch:   5, updates:     5500, train loss:  1.317, train acc: 0.027
time: 239.566, epoch:   5, updates:     6000, train loss:  3.602, train acc: 0.077
time: 243.351, epoch:   5, updates:     6500, train loss:  3.600, train acc: 0.076
time: 175.804, epoch:   6, updates:     7000, train loss:  2.487, train acc: 0.055
time: 251.116, epoch:   6, updates:     7500, train loss:  3.496, train acc: 0.079
time:  9.311, epoch:   7, updates:     8000, train loss:  0.143, train acc: 0.003
time: 239.893, epoch:   7, updates:     8500, train loss:  3.461, train acc: 0.080
time: 234.359, epoch:   7, updates:     9000, train loss:  3.423, train acc: 0.081
time: 89.763, epoch:   8, updates:     9500, train loss:  1.308, train acc: 0.031
time: 231.386, epoch:   8, updates:    10000, train loss:  3.386, train acc: 0.082
time: 241.105, epoch:   8, updates:    10500, train loss:  3.367, train acc: 0.083
time: 169.654, epoch:   9, updates:    11000, train loss:  2.451, train acc: 0.060
time: 232.782, epoch:   9, updates:    11500, train loss:  3.350, train acc: 0.084
time: 14.128, epoch:  10, updates:    12000, train loss:  0.207, train acc: 0.005
time: 238.036, epoch:  10, updates:    12500, train loss:  3.449, train acc: 0.082
time: 238.111, epoch:  10, updates:    13000, train loss:  3.406, train acc: 0.083
Best bleu score: 0.00
